{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create scraping function using pushshiftAPI\n",
    "def scrape_data(subreddit):\n",
    "    api = PushshiftAPI()\n",
    "    subreddit_list = list(api.search_submissions(subreddit=subreddit, filter=['title','subreddit'], limit=15000))\n",
    "    \n",
    "    #filter list to show title and subbredit only\n",
    "    scrape_list = []\n",
    "    for i in range(len(subreddit_list)):\n",
    "        scrape_dict = {}\n",
    "        scrape_dict['subreddit'] = subreddit_list[i][1]\n",
    "        scrape_dict['title'] = subreddit_list[i][2]\n",
    "        scrape_list.append(scrape_dict)\n",
    "    return(scrape_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function and create DataFrame\n",
    "df_nottheonion = pd.DataFrame(scrape_data('nottheonion'))\n",
    "df_onion = pd.DataFrame(scrape_data('theonion'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(dataframe):\n",
    "\n",
    "    # Drop duplicate rows\n",
    "    dataframe.drop_duplicates(subset='title', inplace=True)\n",
    "    \n",
    "    # Remove punctation\n",
    "    dataframe['title'] = dataframe['title'].str.replace('[^\\w\\s]',' ')\n",
    "\n",
    "    # Remove numbers \n",
    "    dataframe['title'] = dataframe['title'].str.replace('[^A-Za-z]',' ')\n",
    "\n",
    "    # Make sure any double-spaces are single \n",
    "    dataframe['title'] = dataframe['title'].str.replace('  ',' ')\n",
    "    dataframe['title'] = dataframe['title'].str.replace('  ',' ')\n",
    "\n",
    "    # Transform all text to lowercase\n",
    "    dataframe['title'] = dataframe['title'].str.lower()\n",
    "    \n",
    "    print(\"New shape:\", dataframe.shape)\n",
    "    return dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape: (13743, 2)\n",
      "New shape: (11593, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>sen lindsey graham rejects trump s call to sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>coronation st actor philip middlemiss wanted o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>san francisco shifts from trashing homeless ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>dollar pushed turkey to china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>nottheonion</td>\n",
       "      <td>greta thunberg added to cnn s expert coronavir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subreddit                                              title\n",
       "0  nottheonion  sen lindsey graham rejects trump s call to sum...\n",
       "1  nottheonion  coronation st actor philip middlemiss wanted o...\n",
       "2  nottheonion  san francisco shifts from trashing homeless ca...\n",
       "3  nottheonion                      dollar pushed turkey to china\n",
       "4  nottheonion  greta thunberg added to cnn s expert coronavir..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data(df_onion)\n",
    "clean_data(df_nottheonion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine df_onion & df_nottheonion with only 'subreddit' (target) and 'title' (predictor) columns\n",
    "df = pd.concat([df_onion[['subreddit', 'title']], df_nottheonion[['subreddit', 'title']]])\n",
    "\n",
    "# Label FakeNews with 1 and RealNews with 0\n",
    "df[\"subreddit\"] = df[\"subreddit\"].map({\"nottheonion\": 0, \"TheOnion\": 1})\n",
    "\n",
    "#save final dataframe to csv\n",
    "df.to_csv('./clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
